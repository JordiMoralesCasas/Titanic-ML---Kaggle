{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21dbfad2",
   "metadata": {},
   "source": [
    "### Titanic - Machine Learning from Disaster\n",
    "\n",
    "https://www.kaggle.com/competitions/titanic/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "c75f3186",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.nn import BCELoss\n",
    "import torch.optim as optim\n",
    "\n",
    "import sklearn as sk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "46a3881a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check GPU runtime type... \n",
      "Change Runtype Type in top menu for GPU acceleration\n"
     ]
    }
   ],
   "source": [
    "print('Check GPU runtime type... ')\n",
    "use_cuda = torch.cuda.is_available()\n",
    "use_cuda=False\n",
    "if not use_cuda:\n",
    "    device = \"cpu\"\n",
    "    print('Change Runtype Type in top menu for GPU acceleration')\n",
    "else:\n",
    "    device = \"cuda\"\n",
    "    print('OK!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "0f7cdd23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 418)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData = pd.read_csv(\"Data/train.csv\")\n",
    "testData = pd.read_csv(\"Data/test.csv\")\n",
    "len(trainData), len(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "613bc78b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived\n",
       "0    549\n",
       "1    342\n",
       "dtype: int64"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData.value_counts(\"Survived\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "ba451558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>is_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304</th>\n",
       "      <td>1305</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>Spector, Mr. Woolf</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A.5. 3236</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>1306</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Oliva y Ocana, Dona. Fermina</td>\n",
       "      <td>female</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17758</td>\n",
       "      <td>108.9000</td>\n",
       "      <td>C105</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>1307</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>Saether, Mr. Simon Sivertsen</td>\n",
       "      <td>male</td>\n",
       "      <td>38.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SOTON/O.Q. 3101262</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>1308</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>Ware, Mr. Frederick</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>359309</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>1309</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>Peter, Master. Michael J</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2668</td>\n",
       "      <td>22.3583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1309 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      PassengerId  Survived  Pclass  \\\n",
       "0               1       0.0       3   \n",
       "1               2       1.0       1   \n",
       "2               3       1.0       3   \n",
       "3               4       1.0       1   \n",
       "4               5       0.0       3   \n",
       "...           ...       ...     ...   \n",
       "1304         1305       NaN       3   \n",
       "1305         1306       NaN       1   \n",
       "1306         1307       NaN       3   \n",
       "1307         1308       NaN       3   \n",
       "1308         1309       NaN       3   \n",
       "\n",
       "                                                   Name     Sex   Age  SibSp  \\\n",
       "0                               Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1     Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                                Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3          Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                              Allen, Mr. William Henry    male  35.0      0   \n",
       "...                                                 ...     ...   ...    ...   \n",
       "1304                                 Spector, Mr. Woolf    male   NaN      0   \n",
       "1305                       Oliva y Ocana, Dona. Fermina  female  39.0      0   \n",
       "1306                       Saether, Mr. Simon Sivertsen    male  38.5      0   \n",
       "1307                                Ware, Mr. Frederick    male   NaN      0   \n",
       "1308                           Peter, Master. Michael J    male   NaN      1   \n",
       "\n",
       "      Parch              Ticket      Fare Cabin Embarked  is_train  \n",
       "0         0           A/5 21171    7.2500   NaN        S         1  \n",
       "1         0            PC 17599   71.2833   C85        C         1  \n",
       "2         0    STON/O2. 3101282    7.9250   NaN        S         1  \n",
       "3         0              113803   53.1000  C123        S         1  \n",
       "4         0              373450    8.0500   NaN        S         1  \n",
       "...     ...                 ...       ...   ...      ...       ...  \n",
       "1304      0           A.5. 3236    8.0500   NaN        S         0  \n",
       "1305      0            PC 17758  108.9000  C105        C         0  \n",
       "1306      0  SOTON/O.Q. 3101262    7.2500   NaN        S         0  \n",
       "1307      0              359309    8.0500   NaN        S         0  \n",
       "1308      1                2668   22.3583   NaN        C         0  \n",
       "\n",
       "[1309 rows x 13 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join both datasets in order to perform preprocessing\n",
    "trainData[\"is_train\"] = 1\n",
    "testData[\"is_train\"] = 0\n",
    "\n",
    "data = trainData.append(testData, ignore_index=True); data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92102453",
   "metadata": {},
   "source": [
    "#### Dropping Useless variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "48333ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(\"Name\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5007e79",
   "metadata": {},
   "source": [
    "#### Treat the rows with na/null values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "a1b31019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId       0\n",
      "Survived        418\n",
      "Pclass            0\n",
      "Sex               0\n",
      "Age             263\n",
      "SibSp             0\n",
      "Parch             0\n",
      "Ticket            0\n",
      "Fare              1\n",
      "Cabin          1014\n",
      "Embarked          2\n",
      "is_train          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "b8184192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age 'NA/Total' rate:  0.20091673032849502\n"
     ]
    }
   ],
   "source": [
    "# NA values for \"Age\"\n",
    "print(\"Age 'NA/Total' rate: \", data[\"Age\"].isna().sum() / len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "d405f87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Age\"] = data[\"Age\"].fillna(data[\"Age\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "c64d9335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cabin 'NA/Total' rate:  0.774637127578304\n"
     ]
    }
   ],
   "source": [
    "print(\"Cabin 'NA/Total' rate: \", data[\"Cabin\"].isna().sum() / len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "92dbcb2b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Since most of the values for \"Cabin\" are unknown, we can omit this column\n",
    "data = data.drop(\"Cabin\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "9aebe937",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fullfilling Fare values with mean\n",
    "data[\"Fare\"] = data[\"Fare\"].fillna(data[\"Fare\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "e3a19feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the unknown \"Embarked\" values are from the test set, we can't its rows. Instead, we fulfill them with the most\n",
    "#  common class\n",
    "data[\"Embarked\"] = data[\"Embarked\"].replace(to_replace=np.nan,\n",
    "                         value=data[\"Embarked\"].value_counts(sort=True).index[0]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8054eba2",
   "metadata": {},
   "source": [
    "####  Encode categorical attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "9ed0e086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping Ticket column (categorical but with mostly unique values)\n",
    "data = data.drop(\"Ticket\", axis=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "06047828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Binarizer for Ticket the 3 different ticket types\n",
    "labBin = LabelBinarizer()\n",
    "embarked_lab = pd.DataFrame(labBin.fit_transform(data[\"Embarked\"]),\n",
    "                           columns = [\"Port_of_\" + i for i in labBin.classes_],\n",
    "                           index=data.index)\n",
    "data = data.join(embarked_lab).drop(\"Embarked\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "468de274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binarizing the genre attribute\n",
    "data[\"Sex\"] = data[\"Sex\"].replace(\"male\", 0)\n",
    "data[\"Sex\"] = data[\"Sex\"].replace(\"female\", 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619e9c94",
   "metadata": {},
   "source": [
    "#### Split dataset, create DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "c5bd0174",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = data[data[\"is_train\"] == 1].drop(\"is_train\", axis=1)\n",
    "\n",
    "trainData, valData, trainTarget, valTarget = train_test_split(\n",
    "                                                    trainData.drop(\"Survived\", axis=1),\n",
    "                                                    trainData[\"Survived\"],\n",
    "                                                    test_size=0.2)\n",
    "\n",
    "# Data for the Kaggle predictions submission\n",
    "testData = data[data[\"is_train\"] == 0].drop([\"is_train\", \"Survived\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "c0eb359d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class titanicDS(Dataset):\n",
    "    \n",
    "    def __init__(self, X, Y=None):\n",
    "        if (type(Y) == type(None)):\n",
    "            # We don't know the ground truth. We have to provide an \n",
    "            # empty vector instead (It will not be used)\n",
    "            self.targets = torch.tensor(np.zeros(len(X)))\n",
    "        else:\n",
    "            self.targets = torch.tensor(Y.tolist())\n",
    "        self.data = torch.tensor(X.values)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.targets[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "60931d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataset = titanicDS(trainData, trainTarget)\n",
    "valDataset = titanicDS(valData, valTarget)\n",
    "testDataset = titanicDS(testData)\n",
    "\n",
    "train_kwargs = {'batch_size': 64}\n",
    "val_kwargs = {'batch_size': 32}\n",
    "test_kwargs  = {'batch_size': 64}\n",
    "\n",
    "if use_cuda:\n",
    "    cuda_kwargs = {'num_workers': 2,\n",
    "                   'pin_memory': True,\n",
    "                   'shuffle': True}\n",
    "    train_kwargs.update(cuda_kwargs)\n",
    "    val_kwargs.update(cuda_kwargs)\n",
    "    test_kwargs.update(cuda_kwargs)\n",
    "\n",
    "trainLoader = DataLoader(trainDataset, **train_kwargs)\n",
    "valLoader = DataLoader(valDataset, **val_kwargs)\n",
    "testLoader = DataLoader(testDataset, **test_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ae7ab2",
   "metadata": {},
   "source": [
    "#### The model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "144b5e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressionModel(torch.nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(LogisticRegressionModel, self).__init__()\n",
    "        self.linear = torch.nn.Linear(input_dim, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output = torch.sigmoid(self.linear(x.float()))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "f91e9d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train fase\n",
    "\n",
    "def train(model, device, loader, criterion, optimizer, epoch, scheduler=None, progress_freq=1):\n",
    "    model.train() #Train mode\n",
    "    \n",
    "    train_loss = []\n",
    "    train_acc = []\n",
    "    for batch_idx, batch in enumerate(loader):\n",
    "        data, target = batch\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        \n",
    "        loss = criterion(output.flatten(), target)\n",
    "        train_loss.append(loss.detach().cpu())\n",
    "        loss.backward() #Backpropagate error\n",
    "        \n",
    "        pred = torch.tensor([1 if  i > 0.5 else 0 for i in output])                                                     \n",
    "        correct = pred.eq(target.view_as(pred)).sum().item()\n",
    "        acc = 100. * correct / loader.batch_size\n",
    "        train_acc.append(acc)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % progress_freq == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f} Accuracy: {}/{} ({:.0f}%)'.format(\n",
    "                epoch, batch_idx * len(data), len(loader.dataset),\n",
    "                100. * batch_idx / len(loader), loss.item(),\n",
    "                correct, len(loader.dataset), acc))\n",
    "            \n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "            \n",
    "    return train_loss, train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "79a84486",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()  # prevent this function from computing gradients \n",
    "def validate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    \n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    for batch_idx, batch in enumerate(loader):\n",
    "        data, target = batch\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        output = model(data).flatten()\n",
    "        \n",
    "        loss = criterion(output, target)\n",
    "        val_loss += loss.item()        \n",
    "        \n",
    "        pred = torch.tensor([1 if  i > 0.5 else 0 for i in output])                                                     \n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    val_loss /= len(loader.dataset)\n",
    "    accuracy = 100. * correct / len(loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        val_loss, correct, len(loader.dataset), accuracy))\n",
    "\n",
    "\n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "2970e346",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/712 (0%)]\tLoss: 44.189743 Accuracy: 20/712 (31%)\n",
      "Train Epoch: 1 [128/712 (17%)]\tLoss: 41.444153 Accuracy: 22/712 (34%)\n",
      "Train Epoch: 1 [256/712 (33%)]\tLoss: 55.268925 Accuracy: 15/712 (23%)\n",
      "Train Epoch: 1 [384/712 (50%)]\tLoss: 37.844337 Accuracy: 28/712 (44%)\n",
      "Train Epoch: 1 [512/712 (67%)]\tLoss: 46.062454 Accuracy: 19/712 (30%)\n",
      "Train Epoch: 1 [640/712 (83%)]\tLoss: 40.743027 Accuracy: 26/712 (41%)\n",
      "\n",
      "Test set: Average loss: 1.2599, Accuracy: 70/179 (39%)\n",
      "\n",
      "Train Epoch: 2 [0/712 (0%)]\tLoss: 42.727795 Accuracy: 20/712 (31%)\n",
      "Train Epoch: 2 [128/712 (17%)]\tLoss: 39.956261 Accuracy: 22/712 (34%)\n",
      "Train Epoch: 2 [256/712 (33%)]\tLoss: 51.118324 Accuracy: 15/712 (23%)\n",
      "Train Epoch: 2 [384/712 (50%)]\tLoss: 36.474014 Accuracy: 28/712 (44%)\n",
      "Train Epoch: 2 [512/712 (67%)]\tLoss: 45.916843 Accuracy: 19/712 (30%)\n",
      "Train Epoch: 2 [640/712 (83%)]\tLoss: 36.815010 Accuracy: 27/712 (42%)\n",
      "\n",
      "Test set: Average loss: 1.2126, Accuracy: 70/179 (39%)\n",
      "\n",
      "Train Epoch: 3 [0/712 (0%)]\tLoss: 39.940594 Accuracy: 20/712 (31%)\n",
      "Train Epoch: 3 [128/712 (17%)]\tLoss: 38.421791 Accuracy: 22/712 (34%)\n",
      "Train Epoch: 3 [256/712 (33%)]\tLoss: 50.799278 Accuracy: 16/712 (25%)\n",
      "Train Epoch: 3 [384/712 (50%)]\tLoss: 36.388523 Accuracy: 28/712 (44%)\n",
      "Train Epoch: 3 [512/712 (67%)]\tLoss: 40.469852 Accuracy: 19/712 (30%)\n",
      "Train Epoch: 3 [640/712 (83%)]\tLoss: 36.777687 Accuracy: 28/712 (44%)\n",
      "\n",
      "Test set: Average loss: 1.1333, Accuracy: 72/179 (40%)\n",
      "\n",
      "Train Epoch: 4 [0/712 (0%)]\tLoss: 38.374733 Accuracy: 21/712 (33%)\n",
      "Train Epoch: 4 [128/712 (17%)]\tLoss: 34.155548 Accuracy: 21/712 (33%)\n",
      "Train Epoch: 4 [256/712 (33%)]\tLoss: 47.759918 Accuracy: 16/712 (25%)\n",
      "Train Epoch: 4 [384/712 (50%)]\tLoss: 32.348091 Accuracy: 26/712 (41%)\n",
      "Train Epoch: 4 [512/712 (67%)]\tLoss: 36.038860 Accuracy: 19/712 (30%)\n",
      "Train Epoch: 4 [640/712 (83%)]\tLoss: 31.418821 Accuracy: 28/712 (44%)\n",
      "\n",
      "Test set: Average loss: 0.9100, Accuracy: 72/179 (40%)\n",
      "\n",
      "Train Epoch: 5 [0/712 (0%)]\tLoss: 28.652939 Accuracy: 19/712 (30%)\n",
      "Train Epoch: 5 [128/712 (17%)]\tLoss: 26.827278 Accuracy: 23/712 (36%)\n",
      "Train Epoch: 5 [256/712 (33%)]\tLoss: 35.214195 Accuracy: 13/712 (20%)\n",
      "Train Epoch: 5 [384/712 (50%)]\tLoss: 16.066273 Accuracy: 26/712 (41%)\n",
      "Train Epoch: 5 [512/712 (67%)]\tLoss: 20.153090 Accuracy: 20/712 (31%)\n",
      "Train Epoch: 5 [640/712 (83%)]\tLoss: 19.013500 Accuracy: 25/712 (39%)\n",
      "\n",
      "Test set: Average loss: 0.3045, Accuracy: 69/179 (39%)\n",
      "\n",
      "Train Epoch: 6 [0/712 (0%)]\tLoss: 11.353128 Accuracy: 18/712 (28%)\n",
      "Train Epoch: 6 [128/712 (17%)]\tLoss: 6.278853 Accuracy: 21/712 (33%)\n",
      "Train Epoch: 6 [256/712 (33%)]\tLoss: 7.065781 Accuracy: 15/712 (23%)\n",
      "Train Epoch: 6 [384/712 (50%)]\tLoss: 4.419585 Accuracy: 28/712 (44%)\n",
      "Train Epoch: 6 [512/712 (67%)]\tLoss: 3.135529 Accuracy: 23/712 (36%)\n",
      "Train Epoch: 6 [640/712 (83%)]\tLoss: 5.210363 Accuracy: 22/712 (34%)\n",
      "\n",
      "Test set: Average loss: 0.1071, Accuracy: 79/179 (44%)\n",
      "\n",
      "Train Epoch: 7 [0/712 (0%)]\tLoss: 3.352335 Accuracy: 29/712 (45%)\n",
      "Train Epoch: 7 [128/712 (17%)]\tLoss: 2.392409 Accuracy: 36/712 (56%)\n",
      "Train Epoch: 7 [256/712 (33%)]\tLoss: 4.110014 Accuracy: 44/712 (69%)\n",
      "Train Epoch: 7 [384/712 (50%)]\tLoss: 4.797887 Accuracy: 35/712 (55%)\n",
      "Train Epoch: 7 [512/712 (67%)]\tLoss: 2.706040 Accuracy: 42/712 (66%)\n",
      "Train Epoch: 7 [640/712 (83%)]\tLoss: 5.602201 Accuracy: 36/712 (56%)\n",
      "\n",
      "Test set: Average loss: 0.1281, Accuracy: 108/179 (60%)\n",
      "\n",
      "Train Epoch: 8 [0/712 (0%)]\tLoss: 3.897781 Accuracy: 43/712 (67%)\n",
      "Train Epoch: 8 [128/712 (17%)]\tLoss: 2.776900 Accuracy: 42/712 (66%)\n",
      "Train Epoch: 8 [256/712 (33%)]\tLoss: 3.970711 Accuracy: 45/712 (70%)\n",
      "Train Epoch: 8 [384/712 (50%)]\tLoss: 3.880239 Accuracy: 33/712 (52%)\n",
      "Train Epoch: 8 [512/712 (67%)]\tLoss: 1.903996 Accuracy: 36/712 (56%)\n",
      "Train Epoch: 8 [640/712 (83%)]\tLoss: 4.068167 Accuracy: 23/712 (36%)\n",
      "\n",
      "Test set: Average loss: 0.0893, Accuracy: 67/179 (37%)\n",
      "\n",
      "Train Epoch: 9 [0/712 (0%)]\tLoss: 2.755146 Accuracy: 22/712 (34%)\n",
      "Train Epoch: 9 [128/712 (17%)]\tLoss: 2.105980 Accuracy: 25/712 (39%)\n",
      "Train Epoch: 9 [256/712 (33%)]\tLoss: 3.890347 Accuracy: 17/712 (27%)\n",
      "Train Epoch: 9 [384/712 (50%)]\tLoss: 2.851400 Accuracy: 28/712 (44%)\n",
      "Train Epoch: 9 [512/712 (67%)]\tLoss: 2.036426 Accuracy: 20/712 (31%)\n",
      "Train Epoch: 9 [640/712 (83%)]\tLoss: 3.485743 Accuracy: 21/712 (33%)\n",
      "\n",
      "Test set: Average loss: 0.0721, Accuracy: 72/179 (40%)\n",
      "\n",
      "Train Epoch: 10 [0/712 (0%)]\tLoss: 2.216013 Accuracy: 26/712 (41%)\n",
      "Train Epoch: 10 [128/712 (17%)]\tLoss: 1.545223 Accuracy: 31/712 (48%)\n",
      "Train Epoch: 10 [256/712 (33%)]\tLoss: 2.516242 Accuracy: 36/712 (56%)\n",
      "Train Epoch: 10 [384/712 (50%)]\tLoss: 2.500177 Accuracy: 30/712 (47%)\n",
      "Train Epoch: 10 [512/712 (67%)]\tLoss: 1.399315 Accuracy: 37/712 (58%)\n",
      "Train Epoch: 10 [640/712 (83%)]\tLoss: 2.592704 Accuracy: 34/712 (53%)\n",
      "\n",
      "Test set: Average loss: 0.0551, Accuracy: 82/179 (46%)\n",
      "\n",
      "Train Epoch: 11 [0/712 (0%)]\tLoss: 1.663325 Accuracy: 29/712 (45%)\n",
      "Train Epoch: 11 [128/712 (17%)]\tLoss: 1.242786 Accuracy: 21/712 (33%)\n",
      "Train Epoch: 11 [256/712 (33%)]\tLoss: 2.063850 Accuracy: 17/712 (27%)\n",
      "Train Epoch: 11 [384/712 (50%)]\tLoss: 1.526275 Accuracy: 25/712 (39%)\n",
      "Train Epoch: 11 [512/712 (67%)]\tLoss: 1.116402 Accuracy: 20/712 (31%)\n",
      "Train Epoch: 11 [640/712 (83%)]\tLoss: 1.629952 Accuracy: 32/712 (50%)\n",
      "\n",
      "Test set: Average loss: 0.0379, Accuracy: 95/179 (53%)\n",
      "\n",
      "Train Epoch: 12 [0/712 (0%)]\tLoss: 1.097039 Accuracy: 37/712 (58%)\n",
      "Train Epoch: 12 [128/712 (17%)]\tLoss: 0.879469 Accuracy: 37/712 (58%)\n",
      "Train Epoch: 12 [256/712 (33%)]\tLoss: 1.050720 Accuracy: 32/712 (50%)\n",
      "Train Epoch: 12 [384/712 (50%)]\tLoss: 0.885333 Accuracy: 30/712 (47%)\n",
      "Train Epoch: 12 [512/712 (67%)]\tLoss: 0.873208 Accuracy: 27/712 (42%)\n",
      "Train Epoch: 12 [640/712 (83%)]\tLoss: 0.770049 Accuracy: 39/712 (61%)\n",
      "\n",
      "Test set: Average loss: 0.0235, Accuracy: 101/179 (56%)\n",
      "\n",
      "Train Epoch: 13 [0/712 (0%)]\tLoss: 0.665520 Accuracy: 38/712 (59%)\n",
      "Train Epoch: 13 [128/712 (17%)]\tLoss: 0.664916 Accuracy: 42/712 (66%)\n",
      "Train Epoch: 13 [256/712 (33%)]\tLoss: 0.607750 Accuracy: 44/712 (69%)\n",
      "Train Epoch: 13 [384/712 (50%)]\tLoss: 0.839250 Accuracy: 35/712 (55%)\n",
      "Train Epoch: 13 [512/712 (67%)]\tLoss: 0.703864 Accuracy: 38/712 (59%)\n",
      "Train Epoch: 13 [640/712 (83%)]\tLoss: 0.687831 Accuracy: 43/712 (67%)\n",
      "\n",
      "Test set: Average loss: 0.0212, Accuracy: 117/179 (65%)\n",
      "\n",
      "Train Epoch: 14 [0/712 (0%)]\tLoss: 0.608098 Accuracy: 45/712 (70%)\n",
      "Train Epoch: 14 [128/712 (17%)]\tLoss: 0.621811 Accuracy: 47/712 (73%)\n",
      "Train Epoch: 14 [256/712 (33%)]\tLoss: 0.566988 Accuracy: 49/712 (77%)\n",
      "Train Epoch: 14 [384/712 (50%)]\tLoss: 0.753844 Accuracy: 41/712 (64%)\n",
      "Train Epoch: 14 [512/712 (67%)]\tLoss: 0.561641 Accuracy: 46/712 (72%)\n",
      "Train Epoch: 14 [640/712 (83%)]\tLoss: 0.568519 Accuracy: 45/712 (70%)\n",
      "\n",
      "Test set: Average loss: 0.0190, Accuracy: 124/179 (69%)\n",
      "\n",
      "Train Epoch: 15 [0/712 (0%)]\tLoss: 0.546929 Accuracy: 49/712 (77%)\n",
      "Train Epoch: 15 [128/712 (17%)]\tLoss: 0.550539 Accuracy: 45/712 (70%)\n",
      "Train Epoch: 15 [256/712 (33%)]\tLoss: 0.540098 Accuracy: 49/712 (77%)\n",
      "Train Epoch: 15 [384/712 (50%)]\tLoss: 0.642217 Accuracy: 39/712 (61%)\n",
      "Train Epoch: 15 [512/712 (67%)]\tLoss: 0.515387 Accuracy: 51/712 (80%)\n",
      "Train Epoch: 15 [640/712 (83%)]\tLoss: 0.538141 Accuracy: 45/712 (70%)\n",
      "\n",
      "Test set: Average loss: 0.0190, Accuracy: 127/179 (71%)\n",
      "\n",
      "Train Epoch: 16 [0/712 (0%)]\tLoss: 0.559914 Accuracy: 46/712 (72%)\n",
      "Train Epoch: 16 [128/712 (17%)]\tLoss: 0.544434 Accuracy: 44/712 (69%)\n",
      "Train Epoch: 16 [256/712 (33%)]\tLoss: 0.549879 Accuracy: 48/712 (75%)\n",
      "Train Epoch: 16 [384/712 (50%)]\tLoss: 0.632841 Accuracy: 39/712 (61%)\n",
      "Train Epoch: 16 [512/712 (67%)]\tLoss: 0.504894 Accuracy: 52/712 (81%)\n",
      "Train Epoch: 16 [640/712 (83%)]\tLoss: 0.532955 Accuracy: 46/712 (72%)\n",
      "\n",
      "Test set: Average loss: 0.0185, Accuracy: 125/179 (70%)\n",
      "\n",
      "Train Epoch: 17 [0/712 (0%)]\tLoss: 0.530366 Accuracy: 48/712 (75%)\n",
      "Train Epoch: 17 [128/712 (17%)]\tLoss: 0.530949 Accuracy: 47/712 (73%)\n",
      "Train Epoch: 17 [256/712 (33%)]\tLoss: 0.547200 Accuracy: 47/712 (73%)\n",
      "Train Epoch: 17 [384/712 (50%)]\tLoss: 0.638467 Accuracy: 40/712 (62%)\n",
      "Train Epoch: 17 [512/712 (67%)]\tLoss: 0.497196 Accuracy: 50/712 (78%)\n",
      "Train Epoch: 17 [640/712 (83%)]\tLoss: 0.534777 Accuracy: 45/712 (70%)\n",
      "\n",
      "Test set: Average loss: 0.0182, Accuracy: 130/179 (73%)\n",
      "\n",
      "Train Epoch: 18 [0/712 (0%)]\tLoss: 0.523097 Accuracy: 48/712 (75%)\n",
      "Train Epoch: 18 [128/712 (17%)]\tLoss: 0.518642 Accuracy: 47/712 (73%)\n",
      "Train Epoch: 18 [256/712 (33%)]\tLoss: 0.553519 Accuracy: 49/712 (77%)\n",
      "Train Epoch: 18 [384/712 (50%)]\tLoss: 0.629176 Accuracy: 41/712 (64%)\n",
      "Train Epoch: 18 [512/712 (67%)]\tLoss: 0.497384 Accuracy: 51/712 (80%)\n",
      "Train Epoch: 18 [640/712 (83%)]\tLoss: 0.526890 Accuracy: 48/712 (75%)\n",
      "\n",
      "Test set: Average loss: 0.0180, Accuracy: 135/179 (75%)\n",
      "\n",
      "Train Epoch: 19 [0/712 (0%)]\tLoss: 0.521125 Accuracy: 48/712 (75%)\n",
      "Train Epoch: 19 [128/712 (17%)]\tLoss: 0.508095 Accuracy: 47/712 (73%)\n",
      "Train Epoch: 19 [256/712 (33%)]\tLoss: 0.562068 Accuracy: 48/712 (75%)\n",
      "Train Epoch: 19 [384/712 (50%)]\tLoss: 0.622908 Accuracy: 42/712 (66%)\n",
      "Train Epoch: 19 [512/712 (67%)]\tLoss: 0.493098 Accuracy: 52/712 (81%)\n",
      "Train Epoch: 19 [640/712 (83%)]\tLoss: 0.523234 Accuracy: 48/712 (75%)\n",
      "\n",
      "Test set: Average loss: 0.0177, Accuracy: 141/179 (79%)\n",
      "\n",
      "Train Epoch: 20 [0/712 (0%)]\tLoss: 0.514859 Accuracy: 52/712 (81%)\n",
      "Train Epoch: 20 [128/712 (17%)]\tLoss: 0.499795 Accuracy: 47/712 (73%)\n",
      "Train Epoch: 20 [256/712 (33%)]\tLoss: 0.568603 Accuracy: 47/712 (73%)\n",
      "Train Epoch: 20 [384/712 (50%)]\tLoss: 0.621448 Accuracy: 42/712 (66%)\n",
      "Train Epoch: 20 [512/712 (67%)]\tLoss: 0.486106 Accuracy: 51/712 (80%)\n",
      "Train Epoch: 20 [640/712 (83%)]\tLoss: 0.517806 Accuracy: 49/712 (77%)\n",
      "\n",
      "Test set: Average loss: 0.0175, Accuracy: 143/179 (80%)\n",
      "\n",
      "Train Epoch: 21 [0/712 (0%)]\tLoss: 0.510245 Accuracy: 52/712 (81%)\n",
      "Train Epoch: 21 [128/712 (17%)]\tLoss: 0.493277 Accuracy: 47/712 (73%)\n",
      "Train Epoch: 21 [256/712 (33%)]\tLoss: 0.583962 Accuracy: 46/712 (72%)\n",
      "Train Epoch: 21 [384/712 (50%)]\tLoss: 0.618577 Accuracy: 43/712 (67%)\n",
      "Train Epoch: 21 [512/712 (67%)]\tLoss: 0.479434 Accuracy: 51/712 (80%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 21 [640/712 (83%)]\tLoss: 0.512655 Accuracy: 50/712 (78%)\n",
      "\n",
      "Test set: Average loss: 0.0173, Accuracy: 145/179 (81%)\n",
      "\n",
      "Train Epoch: 22 [0/712 (0%)]\tLoss: 0.503645 Accuracy: 52/712 (81%)\n",
      "Train Epoch: 22 [128/712 (17%)]\tLoss: 0.489080 Accuracy: 46/712 (72%)\n",
      "Train Epoch: 22 [256/712 (33%)]\tLoss: 0.609292 Accuracy: 42/712 (66%)\n",
      "Train Epoch: 22 [384/712 (50%)]\tLoss: 0.622500 Accuracy: 42/712 (66%)\n",
      "Train Epoch: 22 [512/712 (67%)]\tLoss: 0.474462 Accuracy: 51/712 (80%)\n",
      "Train Epoch: 22 [640/712 (83%)]\tLoss: 0.511994 Accuracy: 53/712 (83%)\n",
      "\n",
      "Test set: Average loss: 0.0171, Accuracy: 143/179 (80%)\n",
      "\n",
      "Train Epoch: 23 [0/712 (0%)]\tLoss: 0.492182 Accuracy: 50/712 (78%)\n",
      "Train Epoch: 23 [128/712 (17%)]\tLoss: 0.485326 Accuracy: 45/712 (70%)\n",
      "Train Epoch: 23 [256/712 (33%)]\tLoss: 0.651108 Accuracy: 38/712 (59%)\n",
      "Train Epoch: 23 [384/712 (50%)]\tLoss: 0.638777 Accuracy: 40/712 (62%)\n",
      "Train Epoch: 23 [512/712 (67%)]\tLoss: 0.469537 Accuracy: 51/712 (80%)\n",
      "Train Epoch: 23 [640/712 (83%)]\tLoss: 0.518014 Accuracy: 52/712 (81%)\n",
      "\n",
      "Test set: Average loss: 0.0171, Accuracy: 135/179 (75%)\n",
      "\n",
      "Train Epoch: 24 [0/712 (0%)]\tLoss: 0.479457 Accuracy: 51/712 (80%)\n",
      "Train Epoch: 24 [128/712 (17%)]\tLoss: 0.477002 Accuracy: 45/712 (70%)\n",
      "Train Epoch: 24 [256/712 (33%)]\tLoss: 0.700792 Accuracy: 36/712 (56%)\n",
      "Train Epoch: 24 [384/712 (50%)]\tLoss: 0.672704 Accuracy: 38/712 (59%)\n",
      "Train Epoch: 24 [512/712 (67%)]\tLoss: 0.463146 Accuracy: 53/712 (83%)\n",
      "Train Epoch: 24 [640/712 (83%)]\tLoss: 0.526035 Accuracy: 51/712 (80%)\n",
      "\n",
      "Test set: Average loss: 0.0174, Accuracy: 131/179 (73%)\n",
      "\n",
      "Train Epoch: 25 [0/712 (0%)]\tLoss: 0.473384 Accuracy: 50/712 (78%)\n",
      "Train Epoch: 25 [128/712 (17%)]\tLoss: 0.462008 Accuracy: 47/712 (73%)\n",
      "Train Epoch: 25 [256/712 (33%)]\tLoss: 0.733744 Accuracy: 34/712 (53%)\n",
      "Train Epoch: 25 [384/712 (50%)]\tLoss: 0.714861 Accuracy: 38/712 (59%)\n",
      "Train Epoch: 25 [512/712 (67%)]\tLoss: 0.457705 Accuracy: 54/712 (84%)\n",
      "Train Epoch: 25 [640/712 (83%)]\tLoss: 0.523572 Accuracy: 52/712 (81%)\n",
      "\n",
      "Test set: Average loss: 0.0178, Accuracy: 126/179 (70%)\n",
      "\n",
      "Train Epoch: 26 [0/712 (0%)]\tLoss: 0.473983 Accuracy: 47/712 (73%)\n",
      "Train Epoch: 26 [128/712 (17%)]\tLoss: 0.445730 Accuracy: 47/712 (73%)\n",
      "Train Epoch: 26 [256/712 (33%)]\tLoss: 0.731008 Accuracy: 35/712 (55%)\n",
      "Train Epoch: 26 [384/712 (50%)]\tLoss: 0.746162 Accuracy: 39/712 (61%)\n",
      "Train Epoch: 26 [512/712 (67%)]\tLoss: 0.459250 Accuracy: 56/712 (88%)\n",
      "Train Epoch: 26 [640/712 (83%)]\tLoss: 0.506491 Accuracy: 52/712 (81%)\n",
      "\n",
      "Test set: Average loss: 0.0179, Accuracy: 126/179 (70%)\n",
      "\n",
      "Train Epoch: 27 [0/712 (0%)]\tLoss: 0.472475 Accuracy: 47/712 (73%)\n",
      "Train Epoch: 27 [128/712 (17%)]\tLoss: 0.435530 Accuracy: 54/712 (84%)\n",
      "Train Epoch: 27 [256/712 (33%)]\tLoss: 0.697654 Accuracy: 38/712 (59%)\n",
      "Train Epoch: 27 [384/712 (50%)]\tLoss: 0.751050 Accuracy: 40/712 (62%)\n",
      "Train Epoch: 27 [512/712 (67%)]\tLoss: 0.469149 Accuracy: 53/712 (83%)\n",
      "Train Epoch: 27 [640/712 (83%)]\tLoss: 0.485017 Accuracy: 54/712 (84%)\n",
      "\n",
      "Test set: Average loss: 0.0176, Accuracy: 128/179 (72%)\n",
      "\n",
      "Train Epoch: 28 [0/712 (0%)]\tLoss: 0.464293 Accuracy: 49/712 (77%)\n",
      "Train Epoch: 28 [128/712 (17%)]\tLoss: 0.430414 Accuracy: 57/712 (89%)\n",
      "Train Epoch: 28 [256/712 (33%)]\tLoss: 0.660145 Accuracy: 38/712 (59%)\n",
      "Train Epoch: 28 [384/712 (50%)]\tLoss: 0.730015 Accuracy: 40/712 (62%)\n",
      "Train Epoch: 28 [512/712 (67%)]\tLoss: 0.476814 Accuracy: 52/712 (81%)\n",
      "Train Epoch: 28 [640/712 (83%)]\tLoss: 0.470670 Accuracy: 55/712 (86%)\n",
      "\n",
      "Test set: Average loss: 0.0170, Accuracy: 134/179 (75%)\n",
      "\n",
      "Train Epoch: 29 [0/712 (0%)]\tLoss: 0.454504 Accuracy: 50/712 (78%)\n",
      "Train Epoch: 29 [128/712 (17%)]\tLoss: 0.423453 Accuracy: 58/712 (91%)\n",
      "Train Epoch: 29 [256/712 (33%)]\tLoss: 0.641415 Accuracy: 40/712 (62%)\n",
      "Train Epoch: 29 [384/712 (50%)]\tLoss: 0.705562 Accuracy: 42/712 (66%)\n",
      "Train Epoch: 29 [512/712 (67%)]\tLoss: 0.474375 Accuracy: 52/712 (81%)\n",
      "Train Epoch: 29 [640/712 (83%)]\tLoss: 0.462891 Accuracy: 55/712 (86%)\n",
      "\n",
      "Test set: Average loss: 0.0167, Accuracy: 136/179 (76%)\n",
      "\n",
      "Train Epoch: 30 [0/712 (0%)]\tLoss: 0.448232 Accuracy: 49/712 (77%)\n",
      "Train Epoch: 30 [128/712 (17%)]\tLoss: 0.415001 Accuracy: 58/712 (91%)\n",
      "Train Epoch: 30 [256/712 (33%)]\tLoss: 0.640068 Accuracy: 39/712 (61%)\n",
      "Train Epoch: 30 [384/712 (50%)]\tLoss: 0.694778 Accuracy: 42/712 (66%)\n",
      "Train Epoch: 30 [512/712 (67%)]\tLoss: 0.468728 Accuracy: 52/712 (81%)\n",
      "Train Epoch: 30 [640/712 (83%)]\tLoss: 0.457198 Accuracy: 55/712 (86%)\n",
      "\n",
      "Test set: Average loss: 0.0165, Accuracy: 141/179 (79%)\n",
      "\n",
      "Train Epoch: 31 [0/712 (0%)]\tLoss: 0.443892 Accuracy: 50/712 (78%)\n",
      "Train Epoch: 31 [128/712 (17%)]\tLoss: 0.407745 Accuracy: 58/712 (91%)\n",
      "Train Epoch: 31 [256/712 (33%)]\tLoss: 0.642469 Accuracy: 39/712 (61%)\n",
      "Train Epoch: 31 [384/712 (50%)]\tLoss: 0.691972 Accuracy: 42/712 (66%)\n",
      "Train Epoch: 31 [512/712 (67%)]\tLoss: 0.464423 Accuracy: 53/712 (83%)\n",
      "Train Epoch: 31 [640/712 (83%)]\tLoss: 0.451985 Accuracy: 55/712 (86%)\n",
      "\n",
      "Test set: Average loss: 0.0164, Accuracy: 143/179 (80%)\n",
      "\n",
      "Train Epoch: 32 [0/712 (0%)]\tLoss: 0.440090 Accuracy: 49/712 (77%)\n",
      "Train Epoch: 32 [128/712 (17%)]\tLoss: 0.401412 Accuracy: 58/712 (91%)\n",
      "Train Epoch: 32 [256/712 (33%)]\tLoss: 0.643438 Accuracy: 39/712 (61%)\n",
      "Train Epoch: 32 [384/712 (50%)]\tLoss: 0.689931 Accuracy: 43/712 (67%)\n",
      "Train Epoch: 32 [512/712 (67%)]\tLoss: 0.460974 Accuracy: 53/712 (83%)\n",
      "Train Epoch: 32 [640/712 (83%)]\tLoss: 0.446992 Accuracy: 55/712 (86%)\n",
      "\n",
      "Test set: Average loss: 0.0163, Accuracy: 143/179 (80%)\n",
      "\n",
      "Train Epoch: 33 [0/712 (0%)]\tLoss: 0.436534 Accuracy: 50/712 (78%)\n",
      "Train Epoch: 33 [128/712 (17%)]\tLoss: 0.395474 Accuracy: 58/712 (91%)\n",
      "Train Epoch: 33 [256/712 (33%)]\tLoss: 0.643943 Accuracy: 39/712 (61%)\n",
      "Train Epoch: 33 [384/712 (50%)]\tLoss: 0.687327 Accuracy: 44/712 (69%)\n",
      "Train Epoch: 33 [512/712 (67%)]\tLoss: 0.457398 Accuracy: 53/712 (83%)\n",
      "Train Epoch: 33 [640/712 (83%)]\tLoss: 0.442325 Accuracy: 56/712 (88%)\n",
      "\n",
      "Test set: Average loss: 0.0163, Accuracy: 143/179 (80%)\n",
      "\n",
      "Train Epoch: 34 [0/712 (0%)]\tLoss: 0.433225 Accuracy: 50/712 (78%)\n",
      "Train Epoch: 34 [128/712 (17%)]\tLoss: 0.389831 Accuracy: 58/712 (91%)\n",
      "Train Epoch: 34 [256/712 (33%)]\tLoss: 0.644896 Accuracy: 39/712 (61%)\n",
      "Train Epoch: 34 [384/712 (50%)]\tLoss: 0.684928 Accuracy: 44/712 (69%)\n",
      "Train Epoch: 34 [512/712 (67%)]\tLoss: 0.453664 Accuracy: 53/712 (83%)\n",
      "Train Epoch: 34 [640/712 (83%)]\tLoss: 0.438061 Accuracy: 56/712 (88%)\n",
      "\n",
      "Test set: Average loss: 0.0162, Accuracy: 143/179 (80%)\n",
      "\n",
      "Train Epoch: 35 [0/712 (0%)]\tLoss: 0.430173 Accuracy: 50/712 (78%)\n",
      "Train Epoch: 35 [128/712 (17%)]\tLoss: 0.384509 Accuracy: 58/712 (91%)\n",
      "Train Epoch: 35 [256/712 (33%)]\tLoss: 0.646267 Accuracy: 39/712 (61%)\n",
      "Train Epoch: 35 [384/712 (50%)]\tLoss: 0.682900 Accuracy: 43/712 (67%)\n",
      "Train Epoch: 35 [512/712 (67%)]\tLoss: 0.449871 Accuracy: 53/712 (83%)\n",
      "Train Epoch: 35 [640/712 (83%)]\tLoss: 0.434203 Accuracy: 56/712 (88%)\n",
      "\n",
      "Test set: Average loss: 0.0162, Accuracy: 144/179 (80%)\n",
      "\n",
      "Train Epoch: 36 [0/712 (0%)]\tLoss: 0.427373 Accuracy: 51/712 (80%)\n",
      "Train Epoch: 36 [128/712 (17%)]\tLoss: 0.379490 Accuracy: 59/712 (92%)\n",
      "Train Epoch: 36 [256/712 (33%)]\tLoss: 0.647998 Accuracy: 40/712 (62%)\n",
      "Train Epoch: 36 [384/712 (50%)]\tLoss: 0.681104 Accuracy: 44/712 (69%)\n",
      "Train Epoch: 36 [512/712 (67%)]\tLoss: 0.445985 Accuracy: 53/712 (83%)\n",
      "Train Epoch: 36 [640/712 (83%)]\tLoss: 0.430779 Accuracy: 56/712 (88%)\n",
      "\n",
      "Test set: Average loss: 0.0161, Accuracy: 145/179 (81%)\n",
      "\n",
      "Train Epoch: 37 [0/712 (0%)]\tLoss: 0.424815 Accuracy: 51/712 (80%)\n",
      "Train Epoch: 37 [128/712 (17%)]\tLoss: 0.374742 Accuracy: 59/712 (92%)\n",
      "Train Epoch: 37 [256/712 (33%)]\tLoss: 0.650199 Accuracy: 40/712 (62%)\n",
      "Train Epoch: 37 [384/712 (50%)]\tLoss: 0.679484 Accuracy: 43/712 (67%)\n",
      "Train Epoch: 37 [512/712 (67%)]\tLoss: 0.441959 Accuracy: 53/712 (83%)\n",
      "Train Epoch: 37 [640/712 (83%)]\tLoss: 0.427844 Accuracy: 56/712 (88%)\n",
      "\n",
      "Test set: Average loss: 0.0161, Accuracy: 146/179 (82%)\n",
      "\n",
      "Train Epoch: 38 [0/712 (0%)]\tLoss: 0.422497 Accuracy: 51/712 (80%)\n",
      "Train Epoch: 38 [128/712 (17%)]\tLoss: 0.370240 Accuracy: 59/712 (92%)\n",
      "Train Epoch: 38 [256/712 (33%)]\tLoss: 0.653010 Accuracy: 40/712 (62%)\n",
      "Train Epoch: 38 [384/712 (50%)]\tLoss: 0.678005 Accuracy: 43/712 (67%)\n",
      "Train Epoch: 38 [512/712 (67%)]\tLoss: 0.437755 Accuracy: 53/712 (83%)\n",
      "Train Epoch: 38 [640/712 (83%)]\tLoss: 0.425474 Accuracy: 56/712 (88%)\n",
      "\n",
      "Test set: Average loss: 0.0161, Accuracy: 145/179 (81%)\n",
      "\n",
      "Train Epoch: 39 [0/712 (0%)]\tLoss: 0.420412 Accuracy: 51/712 (80%)\n",
      "Train Epoch: 39 [128/712 (17%)]\tLoss: 0.365970 Accuracy: 59/712 (92%)\n",
      "Train Epoch: 39 [256/712 (33%)]\tLoss: 0.656581 Accuracy: 40/712 (62%)\n",
      "Train Epoch: 39 [384/712 (50%)]\tLoss: 0.676574 Accuracy: 43/712 (67%)\n",
      "Train Epoch: 39 [512/712 (67%)]\tLoss: 0.433344 Accuracy: 54/712 (84%)\n",
      "Train Epoch: 39 [640/712 (83%)]\tLoss: 0.423768 Accuracy: 55/712 (86%)\n",
      "\n",
      "Test set: Average loss: 0.0161, Accuracy: 145/179 (81%)\n",
      "\n",
      "Train Epoch: 40 [0/712 (0%)]\tLoss: 0.418543 Accuracy: 52/712 (81%)\n",
      "Train Epoch: 40 [128/712 (17%)]\tLoss: 0.361938 Accuracy: 59/712 (92%)\n",
      "Train Epoch: 40 [256/712 (33%)]\tLoss: 0.661069 Accuracy: 40/712 (62%)\n",
      "Train Epoch: 40 [384/712 (50%)]\tLoss: 0.674999 Accuracy: 42/712 (66%)\n",
      "Train Epoch: 40 [512/712 (67%)]\tLoss: 0.428719 Accuracy: 54/712 (84%)\n",
      "Train Epoch: 40 [640/712 (83%)]\tLoss: 0.422851 Accuracy: 55/712 (86%)\n",
      "\n",
      "Test set: Average loss: 0.0161, Accuracy: 145/179 (81%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 41 [0/712 (0%)]\tLoss: 0.416852 Accuracy: 52/712 (81%)\n",
      "Train Epoch: 41 [128/712 (17%)]\tLoss: 0.358186 Accuracy: 59/712 (92%)\n",
      "Train Epoch: 41 [256/712 (33%)]\tLoss: 0.666603 Accuracy: 40/712 (62%)\n",
      "Train Epoch: 41 [384/712 (50%)]\tLoss: 0.672922 Accuracy: 42/712 (66%)\n",
      "Train Epoch: 41 [512/712 (67%)]\tLoss: 0.423921 Accuracy: 54/712 (84%)\n",
      "Train Epoch: 41 [640/712 (83%)]\tLoss: 0.422847 Accuracy: 55/712 (86%)\n",
      "\n",
      "Test set: Average loss: 0.0161, Accuracy: 145/179 (81%)\n",
      "\n",
      "Train Epoch: 42 [0/712 (0%)]\tLoss: 0.415267 Accuracy: 52/712 (81%)\n",
      "Train Epoch: 42 [128/712 (17%)]\tLoss: 0.354835 Accuracy: 58/712 (91%)\n",
      "Train Epoch: 42 [256/712 (33%)]\tLoss: 0.673184 Accuracy: 40/712 (62%)\n",
      "Train Epoch: 42 [384/712 (50%)]\tLoss: 0.669706 Accuracy: 42/712 (66%)\n",
      "Train Epoch: 42 [512/712 (67%)]\tLoss: 0.419102 Accuracy: 54/712 (84%)\n",
      "Train Epoch: 42 [640/712 (83%)]\tLoss: 0.423811 Accuracy: 55/712 (86%)\n",
      "\n",
      "Test set: Average loss: 0.0160, Accuracy: 145/179 (81%)\n",
      "\n",
      "Train Epoch: 43 [0/712 (0%)]\tLoss: 0.413662 Accuracy: 52/712 (81%)\n",
      "Train Epoch: 43 [128/712 (17%)]\tLoss: 0.352148 Accuracy: 58/712 (91%)\n",
      "Train Epoch: 43 [256/712 (33%)]\tLoss: 0.680459 Accuracy: 39/712 (61%)\n",
      "Train Epoch: 43 [384/712 (50%)]\tLoss: 0.664296 Accuracy: 43/712 (67%)\n",
      "Train Epoch: 43 [512/712 (67%)]\tLoss: 0.414601 Accuracy: 54/712 (84%)\n",
      "Train Epoch: 43 [640/712 (83%)]\tLoss: 0.425550 Accuracy: 55/712 (86%)\n",
      "\n",
      "Test set: Average loss: 0.0160, Accuracy: 145/179 (81%)\n",
      "\n",
      "Train Epoch: 44 [0/712 (0%)]\tLoss: 0.411876 Accuracy: 51/712 (80%)\n",
      "Train Epoch: 44 [128/712 (17%)]\tLoss: 0.350594 Accuracy: 58/712 (91%)\n",
      "Train Epoch: 44 [256/712 (33%)]\tLoss: 0.687333 Accuracy: 39/712 (61%)\n",
      "Train Epoch: 44 [384/712 (50%)]\tLoss: 0.655143 Accuracy: 43/712 (67%)\n",
      "Train Epoch: 44 [512/712 (67%)]\tLoss: 0.411011 Accuracy: 57/712 (89%)\n",
      "Train Epoch: 44 [640/712 (83%)]\tLoss: 0.427303 Accuracy: 57/712 (89%)\n",
      "\n",
      "Test set: Average loss: 0.0159, Accuracy: 145/179 (81%)\n",
      "\n",
      "Train Epoch: 45 [0/712 (0%)]\tLoss: 0.409836 Accuracy: 51/712 (80%)\n",
      "Train Epoch: 45 [128/712 (17%)]\tLoss: 0.350843 Accuracy: 58/712 (91%)\n",
      "Train Epoch: 45 [256/712 (33%)]\tLoss: 0.691436 Accuracy: 38/712 (59%)\n",
      "Train Epoch: 45 [384/712 (50%)]\tLoss: 0.640447 Accuracy: 45/712 (70%)\n",
      "Train Epoch: 45 [512/712 (67%)]\tLoss: 0.409097 Accuracy: 57/712 (89%)\n",
      "Train Epoch: 45 [640/712 (83%)]\tLoss: 0.427395 Accuracy: 56/712 (88%)\n",
      "\n",
      "Test set: Average loss: 0.0156, Accuracy: 148/179 (83%)\n",
      "\n",
      "Train Epoch: 46 [0/712 (0%)]\tLoss: 0.407929 Accuracy: 51/712 (80%)\n",
      "Train Epoch: 46 [128/712 (17%)]\tLoss: 0.353469 Accuracy: 56/712 (88%)\n",
      "Train Epoch: 46 [256/712 (33%)]\tLoss: 0.688951 Accuracy: 39/712 (61%)\n",
      "Train Epoch: 46 [384/712 (50%)]\tLoss: 0.619109 Accuracy: 46/712 (72%)\n",
      "Train Epoch: 46 [512/712 (67%)]\tLoss: 0.409395 Accuracy: 56/712 (88%)\n",
      "Train Epoch: 46 [640/712 (83%)]\tLoss: 0.423394 Accuracy: 56/712 (88%)\n",
      "\n",
      "Test set: Average loss: 0.0154, Accuracy: 148/179 (83%)\n",
      "\n",
      "Train Epoch: 47 [0/712 (0%)]\tLoss: 0.407648 Accuracy: 50/712 (78%)\n",
      "Train Epoch: 47 [128/712 (17%)]\tLoss: 0.358178 Accuracy: 56/712 (88%)\n",
      "Train Epoch: 47 [256/712 (33%)]\tLoss: 0.675837 Accuracy: 40/712 (62%)\n",
      "Train Epoch: 47 [384/712 (50%)]\tLoss: 0.592520 Accuracy: 45/712 (70%)\n",
      "Train Epoch: 47 [512/712 (67%)]\tLoss: 0.411539 Accuracy: 56/712 (88%)\n",
      "Train Epoch: 47 [640/712 (83%)]\tLoss: 0.413637 Accuracy: 55/712 (86%)\n",
      "\n",
      "Test set: Average loss: 0.0151, Accuracy: 149/179 (83%)\n",
      "\n",
      "Train Epoch: 48 [0/712 (0%)]\tLoss: 0.411901 Accuracy: 51/712 (80%)\n",
      "Train Epoch: 48 [128/712 (17%)]\tLoss: 0.362980 Accuracy: 56/712 (88%)\n",
      "Train Epoch: 48 [256/712 (33%)]\tLoss: 0.651125 Accuracy: 42/712 (66%)\n",
      "Train Epoch: 48 [384/712 (50%)]\tLoss: 0.566023 Accuracy: 44/712 (69%)\n",
      "Train Epoch: 48 [512/712 (67%)]\tLoss: 0.413828 Accuracy: 56/712 (88%)\n",
      "Train Epoch: 48 [640/712 (83%)]\tLoss: 0.399858 Accuracy: 55/712 (86%)\n",
      "\n",
      "Test set: Average loss: 0.0150, Accuracy: 149/179 (83%)\n",
      "\n",
      "Train Epoch: 49 [0/712 (0%)]\tLoss: 0.423369 Accuracy: 52/712 (81%)\n",
      "Train Epoch: 49 [128/712 (17%)]\tLoss: 0.364403 Accuracy: 55/712 (86%)\n",
      "Train Epoch: 49 [256/712 (33%)]\tLoss: 0.620156 Accuracy: 43/712 (67%)\n",
      "Train Epoch: 49 [384/712 (50%)]\tLoss: 0.547247 Accuracy: 44/712 (69%)\n",
      "Train Epoch: 49 [512/712 (67%)]\tLoss: 0.413638 Accuracy: 56/712 (88%)\n",
      "Train Epoch: 49 [640/712 (83%)]\tLoss: 0.387878 Accuracy: 56/712 (88%)\n",
      "\n",
      "Test set: Average loss: 0.0150, Accuracy: 148/179 (83%)\n",
      "\n",
      "Train Epoch: 50 [0/712 (0%)]\tLoss: 0.439877 Accuracy: 53/712 (83%)\n",
      "Train Epoch: 50 [128/712 (17%)]\tLoss: 0.359296 Accuracy: 56/712 (88%)\n",
      "Train Epoch: 50 [256/712 (33%)]\tLoss: 0.593341 Accuracy: 44/712 (69%)\n",
      "Train Epoch: 50 [384/712 (50%)]\tLoss: 0.539702 Accuracy: 46/712 (72%)\n",
      "Train Epoch: 50 [512/712 (67%)]\tLoss: 0.409392 Accuracy: 56/712 (88%)\n",
      "Train Epoch: 50 [640/712 (83%)]\tLoss: 0.383059 Accuracy: 56/712 (88%)\n",
      "\n",
      "Test set: Average loss: 0.0151, Accuracy: 148/179 (83%)\n",
      "\n",
      "Train Epoch: 51 [0/712 (0%)]\tLoss: 0.451116 Accuracy: 53/712 (83%)\n",
      "Train Epoch: 51 [128/712 (17%)]\tLoss: 0.348042 Accuracy: 56/712 (88%)\n",
      "Train Epoch: 51 [256/712 (33%)]\tLoss: 0.578466 Accuracy: 46/712 (72%)\n",
      "Train Epoch: 51 [384/712 (50%)]\tLoss: 0.538179 Accuracy: 46/712 (72%)\n",
      "Train Epoch: 51 [512/712 (67%)]\tLoss: 0.404150 Accuracy: 57/712 (89%)\n",
      "Train Epoch: 51 [640/712 (83%)]\tLoss: 0.383855 Accuracy: 55/712 (86%)\n",
      "\n",
      "Test set: Average loss: 0.0150, Accuracy: 148/179 (83%)\n",
      "\n",
      "Train Epoch: 52 [0/712 (0%)]\tLoss: 0.447696 Accuracy: 53/712 (83%)\n",
      "Train Epoch: 52 [128/712 (17%)]\tLoss: 0.336609 Accuracy: 56/712 (88%)\n",
      "Train Epoch: 52 [256/712 (33%)]\tLoss: 0.573912 Accuracy: 46/712 (72%)\n",
      "Train Epoch: 52 [384/712 (50%)]\tLoss: 0.537156 Accuracy: 46/712 (72%)\n",
      "Train Epoch: 52 [512/712 (67%)]\tLoss: 0.402972 Accuracy: 55/712 (86%)\n",
      "Train Epoch: 52 [640/712 (83%)]\tLoss: 0.384099 Accuracy: 56/712 (88%)\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy: 148/179 (83%)\n",
      "\n",
      "Train Epoch: 53 [0/712 (0%)]\tLoss: 0.435153 Accuracy: 52/712 (81%)\n",
      "Train Epoch: 53 [128/712 (17%)]\tLoss: 0.330141 Accuracy: 57/712 (89%)\n",
      "Train Epoch: 53 [256/712 (33%)]\tLoss: 0.573874 Accuracy: 46/712 (72%)\n",
      "Train Epoch: 53 [384/712 (50%)]\tLoss: 0.537262 Accuracy: 46/712 (72%)\n",
      "Train Epoch: 53 [512/712 (67%)]\tLoss: 0.404517 Accuracy: 54/712 (84%)\n",
      "Train Epoch: 53 [640/712 (83%)]\tLoss: 0.382156 Accuracy: 55/712 (86%)\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy: 148/179 (83%)\n",
      "\n",
      "Train Epoch: 54 [0/712 (0%)]\tLoss: 0.424792 Accuracy: 51/712 (80%)\n",
      "Train Epoch: 54 [128/712 (17%)]\tLoss: 0.327322 Accuracy: 57/712 (89%)\n",
      "Train Epoch: 54 [256/712 (33%)]\tLoss: 0.574842 Accuracy: 46/712 (72%)\n",
      "Train Epoch: 54 [384/712 (50%)]\tLoss: 0.537902 Accuracy: 45/712 (70%)\n",
      "Train Epoch: 54 [512/712 (67%)]\tLoss: 0.405551 Accuracy: 53/712 (83%)\n",
      "Train Epoch: 54 [640/712 (83%)]\tLoss: 0.380302 Accuracy: 55/712 (86%)\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy: 148/179 (83%)\n",
      "\n",
      "Train Epoch: 55 [0/712 (0%)]\tLoss: 0.419130 Accuracy: 50/712 (78%)\n",
      "Train Epoch: 55 [128/712 (17%)]\tLoss: 0.325626 Accuracy: 57/712 (89%)\n",
      "Train Epoch: 55 [256/712 (33%)]\tLoss: 0.575141 Accuracy: 46/712 (72%)\n",
      "Train Epoch: 55 [384/712 (50%)]\tLoss: 0.537953 Accuracy: 45/712 (70%)\n",
      "Train Epoch: 55 [512/712 (67%)]\tLoss: 0.406296 Accuracy: 53/712 (83%)\n",
      "Train Epoch: 55 [640/712 (83%)]\tLoss: 0.379255 Accuracy: 56/712 (88%)\n",
      "\n",
      "Test set: Average loss: 0.0148, Accuracy: 148/179 (83%)\n",
      "\n",
      "Train Epoch: 56 [0/712 (0%)]\tLoss: 0.415141 Accuracy: 50/712 (78%)\n",
      "Train Epoch: 56 [128/712 (17%)]\tLoss: 0.324219 Accuracy: 57/712 (89%)\n",
      "Train Epoch: 56 [256/712 (33%)]\tLoss: 0.575027 Accuracy: 46/712 (72%)\n",
      "Train Epoch: 56 [384/712 (50%)]\tLoss: 0.538094 Accuracy: 44/712 (69%)\n",
      "Train Epoch: 56 [512/712 (67%)]\tLoss: 0.407214 Accuracy: 53/712 (83%)\n",
      "Train Epoch: 56 [640/712 (83%)]\tLoss: 0.378297 Accuracy: 56/712 (88%)\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy: 148/179 (83%)\n",
      "\n",
      "Train Epoch: 57 [0/712 (0%)]\tLoss: 0.411366 Accuracy: 50/712 (78%)\n",
      "Train Epoch: 57 [128/712 (17%)]\tLoss: 0.323054 Accuracy: 57/712 (89%)\n",
      "Train Epoch: 57 [256/712 (33%)]\tLoss: 0.575116 Accuracy: 46/712 (72%)\n",
      "Train Epoch: 57 [384/712 (50%)]\tLoss: 0.538378 Accuracy: 44/712 (69%)\n",
      "Train Epoch: 57 [512/712 (67%)]\tLoss: 0.407878 Accuracy: 53/712 (83%)\n",
      "Train Epoch: 57 [640/712 (83%)]\tLoss: 0.377278 Accuracy: 56/712 (88%)\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy: 149/179 (83%)\n",
      "\n",
      "Train Epoch: 58 [0/712 (0%)]\tLoss: 0.408366 Accuracy: 50/712 (78%)\n",
      "Train Epoch: 58 [128/712 (17%)]\tLoss: 0.322052 Accuracy: 57/712 (89%)\n",
      "Train Epoch: 58 [256/712 (33%)]\tLoss: 0.575170 Accuracy: 46/712 (72%)\n",
      "Train Epoch: 58 [384/712 (50%)]\tLoss: 0.538443 Accuracy: 44/712 (69%)\n",
      "Train Epoch: 58 [512/712 (67%)]\tLoss: 0.408392 Accuracy: 53/712 (83%)\n",
      "Train Epoch: 58 [640/712 (83%)]\tLoss: 0.376418 Accuracy: 56/712 (88%)\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy: 149/179 (83%)\n",
      "\n",
      "Train Epoch: 59 [0/712 (0%)]\tLoss: 0.405921 Accuracy: 50/712 (78%)\n",
      "Train Epoch: 59 [128/712 (17%)]\tLoss: 0.321160 Accuracy: 57/712 (89%)\n",
      "Train Epoch: 59 [256/712 (33%)]\tLoss: 0.575140 Accuracy: 46/712 (72%)\n",
      "Train Epoch: 59 [384/712 (50%)]\tLoss: 0.538484 Accuracy: 44/712 (69%)\n",
      "Train Epoch: 59 [512/712 (67%)]\tLoss: 0.408869 Accuracy: 53/712 (83%)\n",
      "Train Epoch: 59 [640/712 (83%)]\tLoss: 0.375610 Accuracy: 56/712 (88%)\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy: 149/179 (83%)\n",
      "\n",
      "Train Epoch: 60 [0/712 (0%)]\tLoss: 0.403798 Accuracy: 49/712 (77%)\n",
      "Train Epoch: 60 [128/712 (17%)]\tLoss: 0.320339 Accuracy: 57/712 (89%)\n",
      "Train Epoch: 60 [256/712 (33%)]\tLoss: 0.575107 Accuracy: 47/712 (73%)\n",
      "Train Epoch: 60 [384/712 (50%)]\tLoss: 0.538454 Accuracy: 44/712 (69%)\n",
      "Train Epoch: 60 [512/712 (67%)]\tLoss: 0.409246 Accuracy: 53/712 (83%)\n",
      "Train Epoch: 60 [640/712 (83%)]\tLoss: 0.374855 Accuracy: 56/712 (88%)\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy: 149/179 (83%)\n",
      "\n",
      "Train Epoch: 61 [0/712 (0%)]\tLoss: 0.402020 Accuracy: 50/712 (78%)\n",
      "Train Epoch: 61 [128/712 (17%)]\tLoss: 0.319567 Accuracy: 57/712 (89%)\n",
      "Train Epoch: 61 [256/712 (33%)]\tLoss: 0.575020 Accuracy: 47/712 (73%)\n",
      "Train Epoch: 61 [384/712 (50%)]\tLoss: 0.538367 Accuracy: 44/712 (69%)\n",
      "Train Epoch: 61 [512/712 (67%)]\tLoss: 0.409617 Accuracy: 53/712 (83%)\n",
      "Train Epoch: 61 [640/712 (83%)]\tLoss: 0.374149 Accuracy: 56/712 (88%)\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy: 149/179 (83%)\n",
      "\n",
      "Train Epoch: 62 [0/712 (0%)]\tLoss: 0.400472 Accuracy: 50/712 (78%)\n",
      "Train Epoch: 62 [128/712 (17%)]\tLoss: 0.318834 Accuracy: 57/712 (89%)\n",
      "Train Epoch: 62 [256/712 (33%)]\tLoss: 0.574902 Accuracy: 47/712 (73%)\n",
      "Train Epoch: 62 [384/712 (50%)]\tLoss: 0.538248 Accuracy: 44/712 (69%)\n",
      "Train Epoch: 62 [512/712 (67%)]\tLoss: 0.409975 Accuracy: 53/712 (83%)\n",
      "Train Epoch: 62 [640/712 (83%)]\tLoss: 0.373483 Accuracy: 56/712 (88%)\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy: 149/179 (83%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 63 [0/712 (0%)]\tLoss: 0.399147 Accuracy: 50/712 (78%)\n",
      "Train Epoch: 63 [128/712 (17%)]\tLoss: 0.318131 Accuracy: 57/712 (89%)\n",
      "Train Epoch: 63 [256/712 (33%)]\tLoss: 0.574739 Accuracy: 47/712 (73%)\n",
      "Train Epoch: 63 [384/712 (50%)]\tLoss: 0.538112 Accuracy: 43/712 (67%)\n",
      "Train Epoch: 63 [512/712 (67%)]\tLoss: 0.410373 Accuracy: 53/712 (83%)\n",
      "Train Epoch: 63 [640/712 (83%)]\tLoss: 0.372851 Accuracy: 56/712 (88%)\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy: 149/179 (83%)\n",
      "\n",
      "Train Epoch: 64 [0/712 (0%)]\tLoss: 0.398002 Accuracy: 50/712 (78%)\n",
      "Train Epoch: 64 [128/712 (17%)]\tLoss: 0.317451 Accuracy: 57/712 (89%)\n",
      "Train Epoch: 64 [256/712 (33%)]\tLoss: 0.574534 Accuracy: 47/712 (73%)\n",
      "Train Epoch: 64 [384/712 (50%)]\tLoss: 0.537985 Accuracy: 43/712 (67%)\n",
      "Train Epoch: 64 [512/712 (67%)]\tLoss: 0.410832 Accuracy: 53/712 (83%)\n",
      "Train Epoch: 64 [640/712 (83%)]\tLoss: 0.372253 Accuracy: 56/712 (88%)\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy: 149/179 (83%)\n",
      "\n",
      "Train Epoch: 65 [0/712 (0%)]\tLoss: 0.397027 Accuracy: 50/712 (78%)\n",
      "Train Epoch: 65 [128/712 (17%)]\tLoss: 0.316794 Accuracy: 57/712 (89%)\n",
      "Train Epoch: 65 [256/712 (33%)]\tLoss: 0.574283 Accuracy: 47/712 (73%)\n",
      "Train Epoch: 65 [384/712 (50%)]\tLoss: 0.537909 Accuracy: 44/712 (69%)\n",
      "Train Epoch: 65 [512/712 (67%)]\tLoss: 0.411390 Accuracy: 53/712 (83%)\n",
      "Train Epoch: 65 [640/712 (83%)]\tLoss: 0.371694 Accuracy: 56/712 (88%)\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy: 149/179 (83%)\n",
      "\n",
      "Train Epoch: 66 [0/712 (0%)]\tLoss: 0.396219 Accuracy: 50/712 (78%)\n",
      "Train Epoch: 66 [128/712 (17%)]\tLoss: 0.316161 Accuracy: 57/712 (89%)\n",
      "Train Epoch: 66 [256/712 (33%)]\tLoss: 0.573987 Accuracy: 47/712 (73%)\n",
      "Train Epoch: 66 [384/712 (50%)]\tLoss: 0.537941 Accuracy: 44/712 (69%)\n",
      "Train Epoch: 66 [512/712 (67%)]\tLoss: 0.412078 Accuracy: 53/712 (83%)\n",
      "Train Epoch: 66 [640/712 (83%)]\tLoss: 0.371195 Accuracy: 56/712 (88%)\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy: 149/179 (83%)\n",
      "\n",
      "Train Epoch: 67 [0/712 (0%)]\tLoss: 0.395594 Accuracy: 50/712 (78%)\n",
      "Train Epoch: 67 [128/712 (17%)]\tLoss: 0.315559 Accuracy: 57/712 (89%)\n",
      "Train Epoch: 67 [256/712 (33%)]\tLoss: 0.573661 Accuracy: 47/712 (73%)\n",
      "Train Epoch: 67 [384/712 (50%)]\tLoss: 0.538183 Accuracy: 45/712 (70%)\n",
      "Train Epoch: 67 [512/712 (67%)]\tLoss: 0.412913 Accuracy: 53/712 (83%)\n",
      "Train Epoch: 67 [640/712 (83%)]\tLoss: 0.370802 Accuracy: 56/712 (88%)\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy: 149/179 (83%)\n",
      "\n",
      "Train Epoch: 68 [0/712 (0%)]\tLoss: 0.395198 Accuracy: 50/712 (78%)\n",
      "Train Epoch: 68 [128/712 (17%)]\tLoss: 0.315000 Accuracy: 57/712 (89%)\n",
      "Train Epoch: 68 [256/712 (33%)]\tLoss: 0.573345 Accuracy: 47/712 (73%)\n",
      "Train Epoch: 68 [384/712 (50%)]\tLoss: 0.538816 Accuracy: 45/712 (70%)\n",
      "Train Epoch: 68 [512/712 (67%)]\tLoss: 0.413869 Accuracy: 53/712 (83%)\n",
      "Train Epoch: 68 [640/712 (83%)]\tLoss: 0.370613 Accuracy: 56/712 (88%)\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy: 149/179 (83%)\n",
      "\n",
      "Train Epoch: 69 [0/712 (0%)]\tLoss: 0.395134 Accuracy: 50/712 (78%)\n",
      "Train Epoch: 69 [128/712 (17%)]\tLoss: 0.314499 Accuracy: 57/712 (89%)\n",
      "Train Epoch: 69 [256/712 (33%)]\tLoss: 0.573138 Accuracy: 47/712 (73%)\n",
      "Train Epoch: 69 [384/712 (50%)]\tLoss: 0.540169 Accuracy: 45/712 (70%)\n",
      "Train Epoch: 69 [512/712 (67%)]\tLoss: 0.414801 Accuracy: 53/712 (83%)\n",
      "Train Epoch: 69 [640/712 (83%)]\tLoss: 0.370805 Accuracy: 56/712 (88%)\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy: 149/179 (83%)\n",
      "\n",
      "Train Epoch: 70 [0/712 (0%)]\tLoss: 0.395621 Accuracy: 49/712 (77%)\n",
      "Train Epoch: 70 [128/712 (17%)]\tLoss: 0.314058 Accuracy: 57/712 (89%)\n",
      "Train Epoch: 70 [256/712 (33%)]\tLoss: 0.573224 Accuracy: 47/712 (73%)\n",
      "Train Epoch: 70 [384/712 (50%)]\tLoss: 0.542846 Accuracy: 45/712 (70%)\n",
      "Train Epoch: 70 [512/712 (67%)]\tLoss: 0.415302 Accuracy: 53/712 (83%)\n",
      "Train Epoch: 70 [640/712 (83%)]\tLoss: 0.371649 Accuracy: 56/712 (88%)\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy: 149/179 (83%)\n",
      "\n",
      "Train Epoch: 71 [0/712 (0%)]\tLoss: 0.397124 Accuracy: 49/712 (77%)\n",
      "Train Epoch: 71 [128/712 (17%)]\tLoss: 0.313641 Accuracy: 57/712 (89%)\n",
      "Train Epoch: 71 [256/712 (33%)]\tLoss: 0.573867 Accuracy: 47/712 (73%)\n",
      "Train Epoch: 71 [384/712 (50%)]\tLoss: 0.547900 Accuracy: 46/712 (72%)\n",
      "Train Epoch: 71 [512/712 (67%)]\tLoss: 0.414534 Accuracy: 53/712 (83%)\n",
      "Train Epoch: 71 [640/712 (83%)]\tLoss: 0.373352 Accuracy: 56/712 (88%)\n",
      "\n",
      "Test set: Average loss: 0.0148, Accuracy: 149/179 (83%)\n",
      "\n",
      "Train Epoch: 72 [0/712 (0%)]\tLoss: 0.400560 Accuracy: 49/712 (77%)\n",
      "Train Epoch: 72 [128/712 (17%)]\tLoss: 0.313194 Accuracy: 57/712 (89%)\n",
      "Train Epoch: 72 [256/712 (33%)]\tLoss: 0.575199 Accuracy: 47/712 (73%)\n",
      "Train Epoch: 72 [384/712 (50%)]\tLoss: 0.556864 Accuracy: 45/712 (70%)\n",
      "Train Epoch: 72 [512/712 (67%)]\tLoss: 0.411355 Accuracy: 53/712 (83%)\n",
      "Train Epoch: 72 [640/712 (83%)]\tLoss: 0.375480 Accuracy: 56/712 (88%)\n",
      "\n",
      "Test set: Average loss: 0.0148, Accuracy: 149/179 (83%)\n",
      "\n",
      "Train Epoch: 73 [0/712 (0%)]\tLoss: 0.407325 Accuracy: 50/712 (78%)\n",
      "Train Epoch: 73 [128/712 (17%)]\tLoss: 0.312996 Accuracy: 57/712 (89%)\n",
      "Train Epoch: 73 [256/712 (33%)]\tLoss: 0.576624 Accuracy: 47/712 (73%)\n",
      "Train Epoch: 73 [384/712 (50%)]\tLoss: 0.570705 Accuracy: 46/712 (72%)\n",
      "Train Epoch: 73 [512/712 (67%)]\tLoss: 0.405569 Accuracy: 53/712 (83%)\n",
      "Train Epoch: 73 [640/712 (83%)]\tLoss: 0.376076 Accuracy: 56/712 (88%)\n",
      "\n",
      "Test set: Average loss: 0.0148, Accuracy: 149/179 (83%)\n",
      "\n",
      "Train Epoch: 74 [0/712 (0%)]\tLoss: 0.417882 Accuracy: 51/712 (80%)\n",
      "Train Epoch: 74 [128/712 (17%)]\tLoss: 0.314773 Accuracy: 57/712 (89%)\n",
      "Train Epoch: 74 [256/712 (33%)]\tLoss: 0.576420 Accuracy: 47/712 (73%)\n",
      "Train Epoch: 74 [384/712 (50%)]\tLoss: 0.586170 Accuracy: 46/712 (72%)\n",
      "Train Epoch: 74 [512/712 (67%)]\tLoss: 0.400155 Accuracy: 53/712 (83%)\n",
      "Train Epoch: 74 [640/712 (83%)]\tLoss: 0.372893 Accuracy: 56/712 (88%)\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy: 147/179 (82%)\n",
      "\n",
      "Train Epoch: 75 [0/712 (0%)]\tLoss: 0.427309 Accuracy: 52/712 (81%)\n",
      "Train Epoch: 75 [128/712 (17%)]\tLoss: 0.322021 Accuracy: 58/712 (91%)\n",
      "Train Epoch: 75 [256/712 (33%)]\tLoss: 0.574203 Accuracy: 47/712 (73%)\n",
      "Train Epoch: 75 [384/712 (50%)]\tLoss: 0.591928 Accuracy: 45/712 (70%)\n",
      "Train Epoch: 75 [512/712 (67%)]\tLoss: 0.399410 Accuracy: 56/712 (88%)\n",
      "Train Epoch: 75 [640/712 (83%)]\tLoss: 0.369254 Accuracy: 56/712 (88%)\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy: 148/179 (83%)\n",
      "\n",
      "Train Epoch: 76 [0/712 (0%)]\tLoss: 0.424229 Accuracy: 51/712 (80%)\n",
      "Train Epoch: 76 [128/712 (17%)]\tLoss: 0.333160 Accuracy: 58/712 (91%)\n",
      "Train Epoch: 76 [256/712 (33%)]\tLoss: 0.575537 Accuracy: 47/712 (73%)\n",
      "Train Epoch: 76 [384/712 (50%)]\tLoss: 0.577705 Accuracy: 46/712 (72%)\n",
      "Train Epoch: 76 [512/712 (67%)]\tLoss: 0.400982 Accuracy: 56/712 (88%)\n",
      "Train Epoch: 76 [640/712 (83%)]\tLoss: 0.371965 Accuracy: 57/712 (89%)\n",
      "\n",
      "Test set: Average loss: 0.0148, Accuracy: 149/179 (83%)\n",
      "\n",
      "Train Epoch: 77 [0/712 (0%)]\tLoss: 0.407829 Accuracy: 50/712 (78%)\n",
      "Train Epoch: 77 [128/712 (17%)]\tLoss: 0.334991 Accuracy: 58/712 (91%)\n",
      "Train Epoch: 77 [256/712 (33%)]\tLoss: 0.582647 Accuracy: 46/712 (72%)\n",
      "Train Epoch: 77 [384/712 (50%)]\tLoss: 0.554703 Accuracy: 45/712 (70%)\n",
      "Train Epoch: 77 [512/712 (67%)]\tLoss: 0.399923 Accuracy: 56/712 (88%)\n",
      "Train Epoch: 77 [640/712 (83%)]\tLoss: 0.375266 Accuracy: 56/712 (88%)\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy: 149/179 (83%)\n",
      "\n",
      "Train Epoch: 78 [0/712 (0%)]\tLoss: 0.395289 Accuracy: 49/712 (77%)\n",
      "Train Epoch: 78 [128/712 (17%)]\tLoss: 0.325371 Accuracy: 58/712 (91%)\n",
      "Train Epoch: 78 [256/712 (33%)]\tLoss: 0.583455 Accuracy: 46/712 (72%)\n",
      "Train Epoch: 78 [384/712 (50%)]\tLoss: 0.543295 Accuracy: 45/712 (70%)\n",
      "Train Epoch: 78 [512/712 (67%)]\tLoss: 0.399811 Accuracy: 54/712 (84%)\n",
      "Train Epoch: 78 [640/712 (83%)]\tLoss: 0.372468 Accuracy: 57/712 (89%)\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy: 149/179 (83%)\n",
      "\n",
      "Train Epoch: 79 [0/712 (0%)]\tLoss: 0.393133 Accuracy: 49/712 (77%)\n",
      "Train Epoch: 79 [128/712 (17%)]\tLoss: 0.319188 Accuracy: 58/712 (91%)\n",
      "Train Epoch: 79 [256/712 (33%)]\tLoss: 0.578981 Accuracy: 47/712 (73%)\n",
      "Train Epoch: 79 [384/712 (50%)]\tLoss: 0.545065 Accuracy: 45/712 (70%)\n",
      "Train Epoch: 79 [512/712 (67%)]\tLoss: 0.400047 Accuracy: 53/712 (83%)\n",
      "Train Epoch: 79 [640/712 (83%)]\tLoss: 0.370523 Accuracy: 56/712 (88%)\n",
      "\n",
      "Test set: Average loss: 0.0148, Accuracy: 149/179 (83%)\n",
      "\n",
      "Train Epoch: 80 [0/712 (0%)]\tLoss: 0.395656 Accuracy: 49/712 (77%)\n",
      "Train Epoch: 80 [128/712 (17%)]\tLoss: 0.320018 Accuracy: 58/712 (91%)\n",
      "Train Epoch: 80 [256/712 (33%)]\tLoss: 0.578612 Accuracy: 47/712 (73%)\n",
      "Train Epoch: 80 [384/712 (50%)]\tLoss: 0.547425 Accuracy: 45/712 (70%)\n",
      "Train Epoch: 80 [512/712 (67%)]\tLoss: 0.399227 Accuracy: 54/712 (84%)\n",
      "Train Epoch: 80 [640/712 (83%)]\tLoss: 0.371325 Accuracy: 57/712 (89%)\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy: 149/179 (83%)\n",
      "\n",
      "Train Epoch: 81 [0/712 (0%)]\tLoss: 0.394676 Accuracy: 49/712 (77%)\n",
      "Train Epoch: 81 [128/712 (17%)]\tLoss: 0.320642 Accuracy: 58/712 (91%)\n",
      "Train Epoch: 81 [256/712 (33%)]\tLoss: 0.580427 Accuracy: 46/712 (72%)\n",
      "Train Epoch: 81 [384/712 (50%)]\tLoss: 0.543174 Accuracy: 45/712 (70%)\n",
      "Train Epoch: 81 [512/712 (67%)]\tLoss: 0.399409 Accuracy: 53/712 (83%)\n",
      "Train Epoch: 81 [640/712 (83%)]\tLoss: 0.371414 Accuracy: 57/712 (89%)\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy: 149/179 (83%)\n",
      "\n",
      "Train Epoch: 82 [0/712 (0%)]\tLoss: 0.392758 Accuracy: 49/712 (77%)\n",
      "Train Epoch: 82 [128/712 (17%)]\tLoss: 0.318341 Accuracy: 58/712 (91%)\n",
      "Train Epoch: 82 [256/712 (33%)]\tLoss: 0.579285 Accuracy: 47/712 (73%)\n",
      "Train Epoch: 82 [384/712 (50%)]\tLoss: 0.542727 Accuracy: 45/712 (70%)\n",
      "Train Epoch: 82 [512/712 (67%)]\tLoss: 0.399644 Accuracy: 53/712 (83%)\n",
      "Train Epoch: 82 [640/712 (83%)]\tLoss: 0.370653 Accuracy: 57/712 (89%)\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy: 149/179 (83%)\n",
      "\n",
      "Train Epoch: 83 [0/712 (0%)]\tLoss: 0.393148 Accuracy: 49/712 (77%)\n",
      "Train Epoch: 83 [128/712 (17%)]\tLoss: 0.318503 Accuracy: 58/712 (91%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 83 [256/712 (33%)]\tLoss: 0.579169 Accuracy: 47/712 (73%)\n",
      "Train Epoch: 83 [384/712 (50%)]\tLoss: 0.542898 Accuracy: 45/712 (70%)\n",
      "Train Epoch: 83 [512/712 (67%)]\tLoss: 0.399388 Accuracy: 53/712 (83%)\n",
      "Train Epoch: 83 [640/712 (83%)]\tLoss: 0.370943 Accuracy: 57/712 (89%)\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy: 149/179 (83%)\n",
      "\n",
      "Train Epoch: 84 [0/712 (0%)]\tLoss: 0.392248 Accuracy: 49/712 (77%)\n",
      "Train Epoch: 84 [128/712 (17%)]\tLoss: 0.317959 Accuracy: 58/712 (91%)\n",
      "Train Epoch: 84 [256/712 (33%)]\tLoss: 0.579327 Accuracy: 47/712 (73%)\n",
      "Train Epoch: 84 [384/712 (50%)]\tLoss: 0.541499 Accuracy: 45/712 (70%)\n",
      "Train Epoch: 84 [512/712 (67%)]\tLoss: 0.399635 Accuracy: 53/712 (83%)\n",
      "Train Epoch: 84 [640/712 (83%)]\tLoss: 0.370570 Accuracy: 57/712 (89%)\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy: 149/179 (83%)\n",
      "\n",
      "Train Epoch: 85 [0/712 (0%)]\tLoss: 0.392090 Accuracy: 49/712 (77%)\n",
      "Train Epoch: 85 [128/712 (17%)]\tLoss: 0.317525 Accuracy: 58/712 (91%)\n",
      "Train Epoch: 85 [256/712 (33%)]\tLoss: 0.578993 Accuracy: 47/712 (73%)\n",
      "Train Epoch: 85 [384/712 (50%)]\tLoss: 0.541685 Accuracy: 45/712 (70%)\n",
      "Train Epoch: 85 [512/712 (67%)]\tLoss: 0.399498 Accuracy: 53/712 (83%)\n",
      "Train Epoch: 85 [640/712 (83%)]\tLoss: 0.370618 Accuracy: 57/712 (89%)\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy: 149/179 (83%)\n",
      "\n",
      "Train Epoch: 86 [0/712 (0%)]\tLoss: 0.391718 Accuracy: 50/712 (78%)\n",
      "Train Epoch: 86 [128/712 (17%)]\tLoss: 0.317269 Accuracy: 58/712 (91%)\n",
      "Train Epoch: 86 [256/712 (33%)]\tLoss: 0.579109 Accuracy: 47/712 (73%)\n",
      "Train Epoch: 86 [384/712 (50%)]\tLoss: 0.540880 Accuracy: 45/712 (70%)\n",
      "Train Epoch: 86 [512/712 (67%)]\tLoss: 0.399627 Accuracy: 53/712 (83%)\n",
      "Train Epoch: 86 [640/712 (83%)]\tLoss: 0.370417 Accuracy: 57/712 (89%)\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy: 149/179 (83%)\n",
      "\n",
      "Train Epoch: 87 [0/712 (0%)]\tLoss: 0.391577 Accuracy: 50/712 (78%)\n",
      "Train Epoch: 87 [128/712 (17%)]\tLoss: 0.317002 Accuracy: 58/712 (91%)\n",
      "Train Epoch: 87 [256/712 (33%)]\tLoss: 0.578969 Accuracy: 47/712 (73%)\n",
      "Train Epoch: 87 [384/712 (50%)]\tLoss: 0.540806 Accuracy: 45/712 (70%)\n",
      "Train Epoch: 87 [512/712 (67%)]\tLoss: 0.399567 Accuracy: 53/712 (83%)\n",
      "Train Epoch: 87 [640/712 (83%)]\tLoss: 0.370421 Accuracy: 57/712 (89%)\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy: 149/179 (83%)\n",
      "\n",
      "Train Epoch: 88 [0/712 (0%)]\tLoss: 0.391286 Accuracy: 50/712 (78%)\n",
      "Train Epoch: 88 [128/712 (17%)]\tLoss: 0.316724 Accuracy: 58/712 (91%)\n",
      "Train Epoch: 88 [256/712 (33%)]\tLoss: 0.578925 Accuracy: 47/712 (73%)\n",
      "Train Epoch: 88 [384/712 (50%)]\tLoss: 0.540443 Accuracy: 45/712 (70%)\n",
      "Train Epoch: 88 [512/712 (67%)]\tLoss: 0.399623 Accuracy: 53/712 (83%)\n",
      "Train Epoch: 88 [640/712 (83%)]\tLoss: 0.370293 Accuracy: 57/712 (89%)\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy: 149/179 (83%)\n",
      "\n",
      "Train Epoch: 89 [0/712 (0%)]\tLoss: 0.391200 Accuracy: 50/712 (78%)\n",
      "Train Epoch: 89 [128/712 (17%)]\tLoss: 0.316615 Accuracy: 58/712 (91%)\n",
      "Train Epoch: 89 [256/712 (33%)]\tLoss: 0.578920 Accuracy: 47/712 (73%)\n",
      "Train Epoch: 89 [384/712 (50%)]\tLoss: 0.540198 Accuracy: 45/712 (70%)\n",
      "Train Epoch: 89 [512/712 (67%)]\tLoss: 0.399627 Accuracy: 53/712 (83%)\n",
      "Train Epoch: 89 [640/712 (83%)]\tLoss: 0.370254 Accuracy: 57/712 (89%)\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy: 149/179 (83%)\n",
      "\n",
      "Train Epoch: 90 [0/712 (0%)]\tLoss: 0.391011 Accuracy: 50/712 (78%)\n",
      "Train Epoch: 90 [128/712 (17%)]\tLoss: 0.316395 Accuracy: 58/712 (91%)\n",
      "Train Epoch: 90 [256/712 (33%)]\tLoss: 0.578825 Accuracy: 47/712 (73%)\n",
      "Train Epoch: 90 [384/712 (50%)]\tLoss: 0.540081 Accuracy: 45/712 (70%)\n",
      "Train Epoch: 90 [512/712 (67%)]\tLoss: 0.399623 Accuracy: 53/712 (83%)\n",
      "Train Epoch: 90 [640/712 (83%)]\tLoss: 0.370208 Accuracy: 57/712 (89%)\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy: 149/179 (83%)\n",
      "\n",
      "Train Epoch: 91 [0/712 (0%)]\tLoss: 0.390891 Accuracy: 50/712 (78%)\n",
      "Train Epoch: 91 [128/712 (17%)]\tLoss: 0.316275 Accuracy: 58/712 (91%)\n",
      "Train Epoch: 91 [256/712 (33%)]\tLoss: 0.578806 Accuracy: 47/712 (73%)\n",
      "Train Epoch: 91 [384/712 (50%)]\tLoss: 0.539875 Accuracy: 45/712 (70%)\n",
      "Train Epoch: 91 [512/712 (67%)]\tLoss: 0.399647 Accuracy: 53/712 (83%)\n",
      "Train Epoch: 91 [640/712 (83%)]\tLoss: 0.370148 Accuracy: 57/712 (89%)\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy: 149/179 (83%)\n",
      "\n",
      "Train Epoch: 92 [0/712 (0%)]\tLoss: 0.390810 Accuracy: 50/712 (78%)\n",
      "Train Epoch: 92 [128/712 (17%)]\tLoss: 0.316181 Accuracy: 58/712 (91%)\n",
      "Train Epoch: 92 [256/712 (33%)]\tLoss: 0.578783 Accuracy: 47/712 (73%)\n",
      "Train Epoch: 92 [384/712 (50%)]\tLoss: 0.539732 Accuracy: 45/712 (70%)\n",
      "Train Epoch: 92 [512/712 (67%)]\tLoss: 0.399655 Accuracy: 53/712 (83%)\n",
      "Train Epoch: 92 [640/712 (83%)]\tLoss: 0.370113 Accuracy: 57/712 (89%)\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy: 149/179 (83%)\n",
      "\n",
      "Train Epoch: 93 [0/712 (0%)]\tLoss: 0.390719 Accuracy: 50/712 (78%)\n",
      "Train Epoch: 93 [128/712 (17%)]\tLoss: 0.316076 Accuracy: 58/712 (91%)\n",
      "Train Epoch: 93 [256/712 (33%)]\tLoss: 0.578740 Accuracy: 47/712 (73%)\n",
      "Train Epoch: 93 [384/712 (50%)]\tLoss: 0.539641 Accuracy: 45/712 (70%)\n",
      "Train Epoch: 93 [512/712 (67%)]\tLoss: 0.399657 Accuracy: 53/712 (83%)\n",
      "Train Epoch: 93 [640/712 (83%)]\tLoss: 0.370087 Accuracy: 57/712 (89%)\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy: 149/179 (83%)\n",
      "\n",
      "Train Epoch: 94 [0/712 (0%)]\tLoss: 0.390644 Accuracy: 50/712 (78%)\n",
      "Train Epoch: 94 [128/712 (17%)]\tLoss: 0.315993 Accuracy: 58/712 (91%)\n",
      "Train Epoch: 94 [256/712 (33%)]\tLoss: 0.578709 Accuracy: 47/712 (73%)\n",
      "Train Epoch: 94 [384/712 (50%)]\tLoss: 0.539553 Accuracy: 45/712 (70%)\n",
      "Train Epoch: 94 [512/712 (67%)]\tLoss: 0.399663 Accuracy: 53/712 (83%)\n",
      "Train Epoch: 94 [640/712 (83%)]\tLoss: 0.370061 Accuracy: 57/712 (89%)\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy: 149/179 (83%)\n",
      "\n",
      "Train Epoch: 95 [0/712 (0%)]\tLoss: 0.390591 Accuracy: 50/712 (78%)\n",
      "Train Epoch: 95 [128/712 (17%)]\tLoss: 0.315933 Accuracy: 58/712 (91%)\n",
      "Train Epoch: 95 [256/712 (33%)]\tLoss: 0.578689 Accuracy: 47/712 (73%)\n",
      "Train Epoch: 95 [384/712 (50%)]\tLoss: 0.539472 Accuracy: 45/712 (70%)\n",
      "Train Epoch: 95 [512/712 (67%)]\tLoss: 0.399672 Accuracy: 53/712 (83%)\n",
      "Train Epoch: 95 [640/712 (83%)]\tLoss: 0.370039 Accuracy: 57/712 (89%)\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy: 149/179 (83%)\n",
      "\n",
      "Train Epoch: 96 [0/712 (0%)]\tLoss: 0.390550 Accuracy: 50/712 (78%)\n",
      "Train Epoch: 96 [128/712 (17%)]\tLoss: 0.315887 Accuracy: 58/712 (91%)\n",
      "Train Epoch: 96 [256/712 (33%)]\tLoss: 0.578672 Accuracy: 47/712 (73%)\n",
      "Train Epoch: 96 [384/712 (50%)]\tLoss: 0.539410 Accuracy: 45/712 (70%)\n",
      "Train Epoch: 96 [512/712 (67%)]\tLoss: 0.399678 Accuracy: 53/712 (83%)\n",
      "Train Epoch: 96 [640/712 (83%)]\tLoss: 0.370022 Accuracy: 57/712 (89%)\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy: 149/179 (83%)\n",
      "\n",
      "Train Epoch: 97 [0/712 (0%)]\tLoss: 0.390519 Accuracy: 50/712 (78%)\n",
      "Train Epoch: 97 [128/712 (17%)]\tLoss: 0.315851 Accuracy: 58/712 (91%)\n",
      "Train Epoch: 97 [256/712 (33%)]\tLoss: 0.578657 Accuracy: 47/712 (73%)\n",
      "Train Epoch: 97 [384/712 (50%)]\tLoss: 0.539364 Accuracy: 45/712 (70%)\n",
      "Train Epoch: 97 [512/712 (67%)]\tLoss: 0.399684 Accuracy: 53/712 (83%)\n",
      "Train Epoch: 97 [640/712 (83%)]\tLoss: 0.370011 Accuracy: 57/712 (89%)\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy: 149/179 (83%)\n",
      "\n",
      "Train Epoch: 98 [0/712 (0%)]\tLoss: 0.390496 Accuracy: 50/712 (78%)\n",
      "Train Epoch: 98 [128/712 (17%)]\tLoss: 0.315823 Accuracy: 58/712 (91%)\n",
      "Train Epoch: 98 [256/712 (33%)]\tLoss: 0.578644 Accuracy: 47/712 (73%)\n",
      "Train Epoch: 98 [384/712 (50%)]\tLoss: 0.539333 Accuracy: 45/712 (70%)\n",
      "Train Epoch: 98 [512/712 (67%)]\tLoss: 0.399688 Accuracy: 53/712 (83%)\n",
      "Train Epoch: 98 [640/712 (83%)]\tLoss: 0.370003 Accuracy: 57/712 (89%)\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy: 149/179 (83%)\n",
      "\n",
      "Train Epoch: 99 [0/712 (0%)]\tLoss: 0.390480 Accuracy: 50/712 (78%)\n",
      "Train Epoch: 99 [128/712 (17%)]\tLoss: 0.315805 Accuracy: 58/712 (91%)\n",
      "Train Epoch: 99 [256/712 (33%)]\tLoss: 0.578635 Accuracy: 47/712 (73%)\n",
      "Train Epoch: 99 [384/712 (50%)]\tLoss: 0.539313 Accuracy: 45/712 (70%)\n",
      "Train Epoch: 99 [512/712 (67%)]\tLoss: 0.399690 Accuracy: 53/712 (83%)\n",
      "Train Epoch: 99 [640/712 (83%)]\tLoss: 0.369999 Accuracy: 57/712 (89%)\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy: 149/179 (83%)\n",
      "\n",
      "Train Epoch: 100 [0/712 (0%)]\tLoss: 0.390472 Accuracy: 50/712 (78%)\n",
      "Train Epoch: 100 [128/712 (17%)]\tLoss: 0.315795 Accuracy: 58/712 (91%)\n",
      "Train Epoch: 100 [256/712 (33%)]\tLoss: 0.578630 Accuracy: 47/712 (73%)\n",
      "Train Epoch: 100 [384/712 (50%)]\tLoss: 0.539305 Accuracy: 45/712 (70%)\n",
      "Train Epoch: 100 [512/712 (67%)]\tLoss: 0.399692 Accuracy: 53/712 (83%)\n",
      "Train Epoch: 100 [640/712 (83%)]\tLoss: 0.369997 Accuracy: 57/712 (89%)\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy: 149/179 (83%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_dim = trainData.shape[1]\n",
    "epochs = 100\n",
    "\n",
    "# Create the model\n",
    "model = LogisticRegressionModel(input_dim)\n",
    "\n",
    "# Adam optimizer as a first guess (adaptative gradient)\n",
    "lr = 1e-2\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# Loss function-Binary Cross Entropy\n",
    "criterion = BCELoss()\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(optimizer, lr, epochs=epochs, steps_per_epoch=len(trainLoader))\n",
    "\n",
    "losses = {\"train\": [], \"val\": []}\n",
    "train_accuracies = []\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train_loss, train_acc = train(model, device, trainLoader, criterion, optimizer, epoch, scheduler, progress_freq=2)\n",
    "    losses[\"train\"].append(np.mean(train_loss)) \n",
    "    train_accuracies.append(np.mean(train_acc))\n",
    "    \n",
    "    epoch_loss = validate(model, valLoader, criterion)\n",
    "    losses[\"val\"].append(epoch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "13efee4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(len(losses[\"train\"])), losses[\"train\"],\n",
    "         np.arange(len(losses[\"val\"])), losses[\"val\"])\n",
    "plt.title('BCE loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "1e0122ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(len(train_accuracies)), train_accuracies)\n",
    "plt.title('Train set accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d0a4d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ee5bc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
